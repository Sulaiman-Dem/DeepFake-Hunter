{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OxEFqBPn5BFB"
      },
      "outputs": [],
      "source": [
        "# For Google Colab imports\n",
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XZJkDRU400Tw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # To create/edit/manipulate a data frame\n",
        "import numpy as np # To perform a wide variety of mathematical operations on arrays\n",
        "from glob import glob # a function that's used to search for files that match a specific file pattern or name\n",
        "import csv # To converts into a readable csv file\n",
        "import os # For high file management\n",
        "\n",
        "# For feature extraction of audio files\n",
        "import librosa\n",
        "import librosa.display\n",
        "from librosa import feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCb9u0Pp52kb",
        "outputId": "f92ac459-950e-43ab-a705-117f213585c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Google Colab for attaching Google Drive data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07VTLnq50sdz"
      },
      "source": [
        "## Audio Data Feature Extraction\n",
        "> 1. ```Zero Crossing Rate:``` The rate of sign-changes of the signal during the duration of a particular frame.\n",
        "> 2. ```Root Mean Square:```  Metering tool that measures the average loudness of an audio track within a window of roughly 300 milliseconds.\n",
        "> 3. ```Mel Frequency Cepstral Coefficients:``` Form a cepstral representation where the frequency bands are not linear but distributed according to the mel-scale.\n",
        "> 4. ```Chromagram:``` Represents the 12 different pitches under an audio file, in one place so that we can understand the classification of the pitches in the audio files.\n",
        "> 5. ```Melspectrogram:``` Scale of pitches that can be felt by the listener to be equal in distance from one another.\n",
        "> 6. ```Spectral Centroid:``` The center of gravity of the spectrum.\n",
        "> 7. ```Spectral Bandwidth:``` The difference between the upper and lower frequencies in a continuous band of frequencies.\n",
        "> 8. ```Spectral Rolloff:``` The frequency below which 90% of the magnitude distribution of the spectrum is concentrated.\n",
        "> 9. ```Spectral Entropy:``` Entropy of the normalized spectral energies for a set of sub-frames.\n",
        "> 10. ```Spectral Flux:``` The squared difference between the normalized magnitudes of the spectra of the two successive frames.\n",
        "\n",
        "***NOTE: We will be using Mel Frequency Cepstral Coefficients,Spectral Centroid, Spectral Bandwidth, Spectral Rolloff, Spectral Flux***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e0GqFniVCn_0"
      },
      "outputs": [],
      "source": [
        "# Noise Injection.\n",
        "def inject_noise(data, sampling_rate = 0.035, threshold = 0.075, random = False):\n",
        "    if random:\n",
        "        sampling_rate = np.random.random() * threshold\n",
        "    noise_amplitude = sampling_rate * np.random.uniform() * np.amax(data)\n",
        "    augmented_data = data + noise_amplitude * np.random.normal(size = data.shape[0])\n",
        "    return augmented_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iK9pnBBnCtTg"
      },
      "outputs": [],
      "source": [
        "# Pitching.\n",
        "def pitching(data, sampling_rate, pitch_factor = 0.7,random = False):\n",
        "    if random:\n",
        "        pitch_factor= np.random.random() * pitch_factor\n",
        "    return librosa.effects.pitch_shift(y = data, sr = sampling_rate, n_steps = pitch_factor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F-skd2JmCyzZ"
      },
      "outputs": [],
      "source": [
        "# Stretching.\n",
        "def stretching(data,r = 0.9):\n",
        "    return librosa.effects.time_stretch(y = data, rate = r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jw9OAh6KC4ZC"
      },
      "outputs": [],
      "source": [
        "# Pipeline function that applies all the audio data augmentation functions we just built.\n",
        "def pipeline(data, sampling_rate):\n",
        "    data = pitching(data, sampling_rate, random = True)\n",
        "    data = inject_noise(data, random = True)\n",
        "    data = stretching(data)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Extractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IfJMpHgN-dmQ"
      },
      "outputs": [],
      "source": [
        "def zero_crossing_rate(data, frame_length, hop_length):\n",
        "    zcr = librosa.feature.zero_crossing_rate(y = data, frame_length = frame_length, hop_length = hop_length)\n",
        "    return np.squeeze(zcr)\n",
        "\n",
        "def root_mean_square(data, frame_length = 2048, hop_length = 512):\n",
        "    rms = librosa.feature.rms(y = data, frame_length = frame_length, hop_length = hop_length)\n",
        "    return np.squeeze(rms)\n",
        "\n",
        "\n",
        "def mel_frequency_cepstral_coefficients(data, sampling_rate, frame_length = 2048, hop_length = 512, flatten:bool = True):\n",
        "    mfcc = librosa.feature.mfcc(y = data,sr = sampling_rate)\n",
        "    return np.squeeze(mfcc.T) if not flatten else np.ravel(mfcc.T)\n",
        "\n",
        "\n",
        "def chroma_stft(data, sampling_rate, frame_length = 2048, hop_length = 512, flatten: bool = True):\n",
        "    short_time_fourier_transform = np.abs(librosa.stft(data))\n",
        "    chroma = librosa.feature.chroma_stft(sr = sampling_rate, S = short_time_fourier_transform)\n",
        "    return np.squeeze(chroma.T) if not flatten else np.ravel(chroma.T)\n",
        "\n",
        "\n",
        "def melspectrogram(data, sampling_rate, frame_length = 2048, hop_length = 512, flatten: bool = True):\n",
        "    melspect = librosa.feature.melspectrogram(y = data, sr = sampling_rate)\n",
        "    return np.squeeze(melspect.T) if not flatten else np.ravel(melspect.T)\n",
        "\n",
        "\n",
        "def spectral_centroid(data, sampling_rate, frame_length = 2048, hop_length = 512):\n",
        "    scentroid = librosa.feature.spectral_centroid(y = data, sr = sampling_rate, n_fft = frame_length, hop_length = hop_length)\n",
        "    return np.squeeze(scentroid)\n",
        "\n",
        "\n",
        "def spectral_bandwidth(data, sampling_rate, frame_length = 2048, hop_length = 512):\n",
        "    sbandwidth = librosa.feature.spectral_bandwidth(y = data, sr = sampling_rate, n_fft = frame_length, hop_length = hop_length)\n",
        "    return np.squeeze(sbandwidth)\n",
        "\n",
        "\n",
        "def spectral_rolloff(data, sampling_rate, frame_length = 2048, hop_length = 512):\n",
        "    srolloff = librosa.feature.spectral_rolloff(y = data, sr = sampling_rate, n_fft = frame_length, hop_length = hop_length)\n",
        "    return np.squeeze(srolloff)\n",
        "\n",
        "\n",
        "def spectral_flux(data, sampling_rate):\n",
        "    sflux = librosa.onset.onset_strength(y = data, sr = sampling_rate)\n",
        "    return np.squeeze(sflux)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Extraction Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TStDpCRtBAiE"
      },
      "outputs": [],
      "source": [
        "def feature_extraction(data, sampling_rate, frame_length = 2048, hop_length = 512):\n",
        "    result = np.array([])\n",
        "    result = np.hstack((result,\n",
        "                        # zero_crossing_rate(data, frame_length, hop_length),\n",
        "                        # root_mean_square(data, frame_length, hop_length),\n",
        "                        mel_frequency_cepstral_coefficients(data, sampling_rate, frame_length, hop_length),\n",
        "                        spectral_centroid(data, sampling_rate, frame_length, hop_length),\n",
        "                        spectral_bandwidth(data, sampling_rate, frame_length, hop_length),\n",
        "                        spectral_rolloff(data, sampling_rate, frame_length, hop_length),\n",
        "                        spectral_flux(data, sampling_rate)\n",
        "                     ))\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6SXfgJBtCESE"
      },
      "outputs": [],
      "source": [
        "# Duration and offset act as placeholders because there is no audio in start and the ending of each audio file is normally below three seconds.\n",
        "def get_features(file_path, duration = 2.5, offset = 0.6):\n",
        "    data, sampling_rate = librosa.load(path = file_path, duration = duration, offset = offset)\n",
        "\n",
        "    # No audio data augmentation.\n",
        "    audio_1 = feature_extraction(data, sampling_rate)\n",
        "    # audio_1 = np.resize(audio_1, (1, 19921))\n",
        "    audio = np.array(audio_1)\n",
        "\n",
        "    # # Inject Noise.\n",
        "    # noise_audio_1 = inject_noise(data, random = True)\n",
        "    # audio_2 =  feature_extraction(noise_audio_1, sampling_rate)\n",
        "    # audio_2.resize((1, 19921))\n",
        "    # audio = np.vstack((audio, audio_2))\n",
        "\n",
        "    # # Pitching.\n",
        "    # pitch_audio_1 = pitching(data, sampling_rate, random = True)\n",
        "    # audio_3 = feature_extraction(pitch_audio_1, sampling_rate)\n",
        "    # audio_3.resize((1, 19921))\n",
        "    # audio = np.vstack((audio, audio_3))\n",
        "\n",
        "    # # Stretching.\n",
        "    # stretch_audio_1 = stretching(data)\n",
        "    # audio_4 = feature_extraction(stretch_audio_1, sampling_rate)\n",
        "    # audio_4.resize((1, 19921))\n",
        "    # audio = np.vstack((audio, audio_4))\n",
        "\n",
        "    # # Pitching and Inject Noise.\n",
        "    # pitch_audio_2 = pitching(data, sampling_rate, random = True)\n",
        "    # pitch_noise_audio_1 = inject_noise(pitch_audio_2, random = True)\n",
        "    # audio_5 = feature_extraction(pitch_noise_audio_1, sampling_rate)\n",
        "    # audio_5.resize((1, 19921))\n",
        "    # audio = np.vstack((audio, audio_5))\n",
        "\n",
        "    # # Stretching and Pitching.\n",
        "    # stretch_audio_2 = stretching(data)\n",
        "    # stretch_pitch_audio_1 = pitching(stretch_audio_2, sampling_rate, random = True)\n",
        "    # audio_6 = feature_extraction(stretch_pitch_audio_1, sampling_rate)\n",
        "    # audio_6.resize((1, 19921))\n",
        "    # audio = np.vstack((audio, audio_6))\n",
        "\n",
        "    # # Pitching, Inject Noise, and Stretching.\n",
        "    # pitch_noise_stretch_audio_1 = pipeline(data, sampling_rate)\n",
        "    # audio_7 =  feature_extraction(pitch_noise_stretch_audio_1, sampling_rate)\n",
        "    # audio_7.resize((1, 19921))\n",
        "    # audio = np.vstack((audio, audio_7))\n",
        "\n",
        "    audio_features = audio\n",
        "\n",
        "    return audio_features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# File path of Audio folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SMnG-Ox8vPM"
      },
      "source": [
        "```FAKE```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-raHdwhs88xO"
      },
      "source": [
        "0. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/fake/Cleaned Spoof-Audio/')\n",
        "\n",
        "1. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/fake/Fake People/')\n",
        "\n",
        "2. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/fake/Generated_Audio_FAKE/ljspeech_hifiGAN/')\n",
        "\n",
        "3. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/fake/Generated_Audio_FAKE/ljspeech_melgan/')\n",
        "\n",
        "4. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/fake/Generated_Audio_FAKE/ljspeech_melgan_large/')\n",
        "\n",
        "5. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/fake/Generated_Audio_FAKE/ljspeech_multi_band_melgan/')\n",
        "\n",
        "6. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/fake/Generated_Audio_FAKE/ljspeech_parallel_wavegan/')\n",
        "\n",
        "7. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/fake/Generated_Audio_FAKE/ljspeech_waveglow/')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1u9lAbr4cDF"
      },
      "source": [
        "```REAL```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwofiuC_4hbV"
      },
      "source": [
        "0. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/real/Real_People/')\n",
        "\n",
        "1. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/real/LJSpeech-1.1/wavs/')\n",
        "\n",
        "2. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/real/Cleaned_Bonafide-Audio/')\n",
        "\n",
        "3. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/real/CREMA-D_REAL/')\n",
        "\n",
        "4. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/real/common_voice_wav_audio/common_voice_10_valid_clips_wav/')\n",
        "\n",
        "5. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/real/common_voice_wav_audio/common_voice_corpus_6-1_valid_clips_wav/')\n",
        "\n",
        "6. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/real/common_voice_wav_audio/common_voice_12_valid_clips_wav/')\n",
        "\n",
        "7. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/real/common_voice_wav_audio/common_voice_13_valid_clips_wav/')\n",
        "\n",
        "8. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/real/common_voice_wav_audio/common_voice_14_valid_clips_wav/')\n",
        "\n",
        "9. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/real/common_voice_wav_audio/common_voice_15_valid_clips_wav/')\n",
        "\n",
        "10. full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/real/common_voice_wav_audio/common_voice_3_valid_clips_wav/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Extraction of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG1RWF3zMeXQ",
        "outputId": "12a9d3e1-1522-4ad4-e75e-1b64d6138615"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
            "  return pitch_tuning(\n"
          ]
        }
      ],
      "source": [
        "def whole_folder_extract(audio_folder):\n",
        "    full_audio_feature_list = []\n",
        "    # Make a path to audio folder\n",
        "    audio_path = os.path.join(os.getcwd(), audio_folder)\n",
        "    for filename in os.listdir(audio_path):\n",
        "        if filename.endswith('.wav'):\n",
        "            # Full path of source file\n",
        "            full_path = os.path.join(audio_path, filename)\n",
        "            audio_features = get_features(full_path)\n",
        "            # Flatten the 2D array into a 1D array before appending\n",
        "            audio_features_flattened = np.array(audio_features).flatten()\n",
        "            full_audio_feature_list.append(audio_features_flattened)\n",
        "    return full_audio_feature_list\n",
        "\n",
        "\n",
        "full_audio_features_list = whole_folder_extract('/content/drive/MyDrive/data/audio/real/common_voice_wav_audio/common_voice_corpus_6-1_valid_clips_wav/')\n",
        "audio_features_df = pd.DataFrame(full_audio_features_list)\n",
        "audio_features_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Checking Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asf4E-TUw8Gt"
      },
      "outputs": [],
      "source": [
        "def inspect_dataframe(input_df):\n",
        "\n",
        "    print('The Null Values:\\n',input_df.isnull().sum().sum())\n",
        "    print('\\n')\n",
        "    # print('The Duplicate Values:\\n',input_df.duplicated().sum())\n",
        "    # print('\\n')\n",
        "    # print('The Description:\\n',input_df.describe())\n",
        "    # print('\\n')\n",
        "    # print('Columns:')\n",
        "    # for col in input_df.columns:\n",
        "    #     print(col)\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i5tBi-FxALT"
      },
      "outputs": [],
      "source": [
        "inspect_dataframe(audio_features_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extracting dataframe as csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_mK79mpmtxK"
      },
      "outputs": [],
      "source": [
        "audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/real/REAL_common_voice_corpus_6-1_feature_extraction_list.csv',  index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# File Path for csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeUBcNqeU01p"
      },
      "source": [
        "```REAL```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcydnP0_4lEI"
      },
      "source": [
        "0. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/real/REAL_voice_recognition_feature_extraction_list.csv',  index=False)\n",
        "\n",
        "1. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/real/REAL_ljSpeech-1.1_feature_extraction_list.csv',  index=False)\n",
        "\n",
        "2. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/real/REAL_bonafide_audio_feature_extraction_list.csv',  index=False)\n",
        "\n",
        "3. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/real/REAL_crema-d_feature_extraction_list.csv',  index=False)\n",
        "\n",
        "4. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/real/REAL_common_voice_10_feature_extraction_list.csv',  index=False)\n",
        "\n",
        "5. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/real/REAL_common_voice_corpus_6-1_feature_extraction_list.csv',  index=False)\n",
        "\n",
        "6. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/real/REAL_common_voice_12_feature_extraction_list.csv',  index=False)\n",
        "\n",
        "7. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/real/REAL_common_voice_13_feature_extraction_list.csv',  index=False)\n",
        "\n",
        "8. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/real/REAL_common_voice_14_feature_extraction_list.csv',  index=False)\n",
        "\n",
        "9. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/real/REAL_common_voice_15_feature_extraction_list.csv',  index=False)\n",
        "\n",
        "10. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/real/REAL_common_voice_3_feature_extraction_list.csv',  index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04dO6-g6Urqx"
      },
      "source": [
        "```Fake```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9o4vuGa9ANf"
      },
      "source": [
        "0. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/fake/FAKE_spoof_audio_features_extraction_list.csv',  index=False)\n",
        "\n",
        "\n",
        "1. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/fake/FAKE_voice_recognition_features_extraction_list.csv',  index=False)\n",
        "\n",
        "\n",
        "2. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/fake/FAKE_ljspeech_hifiGAN_features_extraction_list.csv',  index=False)\n",
        "\n",
        "3. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/fake/FAKE_ljspeech_melgan_features_extraction_list.csv',  index=False)\n",
        "\n",
        "4. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/fake/FAKE_ljspeech_melgan_large_features_extraction_list.csv',  index=False)\n",
        "\n",
        "5. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/fake/FAKE_ljspeech_multi_band_melgan_features_extraction_list.csv',  index=False)\n",
        "\n",
        "6. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/fake/FAKE_ljspeech_parallel_wavegan_features_extraction_list.csv',  index=False)\n",
        "\n",
        "7. audio_features_df.to_csv('/content/drive/MyDrive/data/features/new_features/fake/FAKE_ljspeech_waveglow_features_extraction_list.csv',  index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
